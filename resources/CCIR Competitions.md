---
title: CCIR评测资源
---

#CCIR评测资源：
##<a href=https://www.datafountain.cn/special/BDCI2022-CCIR>CCIR CUP 2022 科大讯飞-全国信息检索挑战杯</a>
###<a href=https://www.datafountain.cn/competitions/572/datasets>赛题一：通用事件属性抽取</a>
####赛题背景：
　　信息抽取（Information Extraction）任务将自然语言中的非结构化信息处理为结构化表达，是处理海量文本数据的重要手段。由于自然语言本身的多样性，及词法、句法的复杂性，信息抽取任务常被认定为人工智能领域的困难问题。
　　
　　事件抽取（Event Extraction）是信息抽取的重要研究方向，在社交媒体、商务金融等垂直领域拥有广阔的应用前景。当前较多事件抽取任务仅识别有限事件类别，面对日常生活中的海量新闻事件存在一定局限性，开放信息抽取（Open Information Extraction）任务较多通过三元组表示相关信息，标注信息丰富度不足、灵活性欠缺。本赛题结合两类任务特点，主要考察事件通用属性抽取，不需人工定义事件类型与模式，同时具备较好的信息丰富性、标注灵活度，便于下游任务进一步分析、处理。

####赛题任务：
　　面向新闻知识库构建、突发事件检测等应用，提供包含新闻事件的多来源文本数据，标注主体、时间、地点等事件通用属性信息，将自然语言中的非结构化信息转为结构化表达，考察信息抽取领域通用事件属性抽取能力准确性。

###<a href=https://www.datafountain.cn/competitions/573>赛题二：基于金融财报中的混合表格与文本数据的问答</a>
####赛题背景：
金融财报是一个公司按照季度或者年度向其股东或者投资者发布的公司经营及财务状况的报告书。金融财报能帮助股东或者投资者了解企业在上一个财务时间段的经营状况，并能进一步帮助他们做出经济决策。金融财报中一般会包含大量的半结构化的表格和非结构化的文本数据。为了能够从金融财报中筛选出有价值的信息，金融行业从业人员往往需要花费大量的时间来阅读和理解这些数据。为了减轻这一环节的工作量，我们希望构建智能的Hybrid QA模型，以辅助金融从业者更快的理解混合有表格和文本内容的金融财报数据。理想的Hybrid QA模型需要能同时理解金融财报中的半结构化的表格数据和非结构化的文本数据，并基于这些数据以自然语言的形式回答一些专业问题。因为金融财报中包含有丰富的数字（如金额，时间等），为了能够回答这些专业的问题，所设计的QA模型往往还需要具备离散推理的能力。


####赛题任务
给定从金融财报中筛选的一个半结构化的表格和几个与该表格相关的段落（一般不少于2个），当收到一个与之相关的自然语言形式的问题后，要求模型能够根据表格和段落给出该问题的相应的答案。

在该任务中，半结构化的表格存储为一个二维数组，与该表格相关的文本段落以及问题都以字符串形式存储。问题分为两种类型：事实类的问题和假设性的问题。其中，事实类的问题是可以基于给定的表格和段落来回答的，如：“What is the net profit in 2019?”。而假设性的问题是通过在事实类的问题中添加一个假设而来，如：“What would the net profit in 2019 be if the revenue in 2019 were $38,473 instead?”
　　
##<a href=https://www.datafountain.cn/special/BDCI2021-CCIR>CCIR CUP 2021 全国信息检索挑战杯</a>
###<a href=https://www.datafountain.cn/competitions/509>赛题一：预训练模型知识量度量</a>
###赛题背景：
近年来，以BERT为代表的预训练模型在各项NLP任务中取得了重大突破。相关研究表明，预训练模型不仅可以学习通用语言表示，还可以学习结构化的知识，包括常识知识和事实知识。为了更深入地理解预训练模型，我们构建数据集来系统地评估模型的知识含量，不仅考察模型预训练阶段所编码的知识量，同时考察模型是否具备推理能力。为此，我们构造了来自不同领域（历史、军事、医学等）、不同类型（事实知识、常识知识）、不同难度（单条知识、多条知识组合）的问题，把对模型知识量的测评，转换为相应的完型填空问题。当模型能成功填充[MASK]标识符时，则说明该模型掌握了相关知识。

我们希望通过考察模型的知识量，驱动业界对于模型知识表示的研究，实现预训练模型向下游任务更有效的知识转移。 本次预训练模型的知识量评估侧重于考察模型的记忆能力，特别是在few-shot或zero-shot情况下的记忆和能力和多知识组合能力，后期会加入更多的推理类问题，以及考察模型本身的泛化能力。
###赛题任务：
本赛题构建了完型填空形式的英文测评数据集，评估预训练模型在9个领域、两大知识类型（事实知识、常识知识）、不同难度任务上的知识含量。


###<a href=https://www.datafountain.cn/competitions/511>赛题二：智能人机交互自然语言理解</a>
###赛题背景：
在产品的研发迭代过程中，为满足用户的各类使用需求，往往需要大量标注数据用于训练才能达成较好的交互效果，而大量的标注数据意味着高昂的成本投入。小样本学习（Few-shot Learning）是机器学习领域近年来新兴的研究方向之一，旨在凭借基础类别中学到的先验知识及少量新类别标记样本，较好的完成对新类别数据的泛化任务，从而减少数据成本投入的需求。另一方面，产品在实际应用中可能经常遇到未经训练的新类别问题，如何识别并处理此种域外问题同样是生产中的常见问题之一。域外检测（Out-of-Distribution Detection）任务旨在帮助产品较好的处理真实使用场景中的未知意图，挖掘出用户的潜在意图，从而帮助提升服务质量。

为了更好的解决智能人机交互产品的自然语言理解任务，本赛题对NLU领域的意图识别及槽位填充任务进行考察。除基本的学习任务外，还期望通过小样本学习任务减少产品对大量新类别标注数据的依赖，通过域外检测任务识别未知意图，摆脱对已知意图的干扰，同时达到尽可能好的学习效果。
###赛题任务：
根据用户与系统的单轮对话，识别对话用户意图并进行槽位填充。除基础的意图识别及槽位填充任务外，本赛题额外包括2个子任务：
人机交互-NLU-1（小样本学习任务）：根据基础意图类别数据及少量含标注的新意图类别样本，完成新意图类别的识别及槽位填充任务。
人机交互-NLU-2（域外意图检测任务）：除识别出训练数据中已知的意图类别外，对于未知意图类别数据进行检测。


###<a href=https://www.datafountain.cn/competitions/510>赛题三：中文命名实体识别算法鲁棒性评测</a>
###赛题背景：
鲁棒性是机器学习模型的一项重要评价指标，主要用于检验模型在面对输入数据的微小变动时，是否依然能保持判断的准确性，也即模型面对一定变化时的表现是否稳定。鲁棒性的高低直接决定了机器学习模型的泛化能力。在现实世界的应用场景中，模型要面对的是更加纷繁复杂的语言应用方式，待处理的数据里包含着更加庞杂的变化。一旦缺乏鲁棒性，模型在现实应用中的性能就会大打折扣。在测试数据集上获得高分是远远不够的，机器学习模型的设计目标是让模型在面对新的外部数据时依然维持精准的判断。因此，为了确保模型的实际应用价值，对模型进行鲁棒性评测是不可或缺的。

近期，复旦大学自然语言处理实验室发布了模型鲁棒性评测平台 TextFlint（textflint.io），该平台涵盖 12 项 NLP 任务，囊括 80 余种数据变形方法，涵盖了领域相关黑盒变形、领域无关黑盒变形、白盒变形、分组抽样、分析报告等等一系列功能，为研究人员提供一个便捷的模型鲁棒性验证方法。为了构建安全可靠的深度学习系统，消除深度学习模型在实际部署应用中的潜在鲁棒性风险，本赛题针对命名实体任务开展鲁棒性评测。本次评测提供给参赛者的原始数据集训练模型，而验证集和测试集由鲁棒性评测工具 TextFlint 产生，以最终排名依据为新的鲁棒性验证集和测试集的性能表现。


###赛题任务：
给定未分好词但有实体标记的中文文本训练数据，设计算法对验证集中词语的实体类型进行预测，其中部分文本经过了鲁棒性评测工具TextFlint的扰动。预测的任务是判断哪些词语是人名(PER)，地理位置(LOC)，机构(ORG)或行政单位(GPE)，并以(B,M,E,S)的格式给出词语的边界。
##CCIR 2020评测
###<a href=https://www.datafountain.cn/competitions/423?CCIR2020>赛题一：疫情期间网民情绪识别</a>
####赛题背景：
新型冠状病毒（COVID-19）感染的肺炎疫情牵动着全国人民的心，全国同舟共济、众志成城，打响了一场没有硝烟的疫情阻击战。习近平指出：要鼓励运用大数据、人工智能、云计算等数字技术，在疫情监测分析、病毒溯源、防控救治、资源调配等方面更好发挥支撑作用。为了帮助政府掌握真实社会舆论情况，科学高效地做好防控宣传和舆情引导工作，本赛题针对疫情相关话题开展网民情绪识别的任务。


####赛题任务：
给定微博ID和微博内容，设计算法对微博内容进行情绪识别，判断微博内容是积极的、消极的还是中性的。

